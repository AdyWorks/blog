# Differential dataflow internals; a work in progress

This post is really meant to be a series of posts about how to represent data managed in [differential dataflow](https://github.com/frankmcsherry/differential-dataflow). As they are topically related and meant to build upon one another, I thought putting them in one place would help record and explain what I was thinking when implementing them. They *may* also be helpful for folks thinking about building interesting things in Rust!

In the spirit of "append only updates", this post will largely be append-only (modulo errors, edits). I'm also going to try and make the development process largely append-only as well: new implementations will be added to older ones, rather than replacing them, allowing us to keep track of where we were and how far we've come. This will probably break at various points, but that is the intent!

This series is going to start out intentionally pedantic and simple, to frame the problem in the simplest language and implementations. We will try and become smarter as we move along, but let's start with simple, and evaluate things as we go. Here is the planned roadmap:

* [Part 0/x: Trait definitions; defining what we require.](https://github.com/frankmcsherry/blog/blob/master/posts/2016-08-03.md#part-0-trait-definitions-defining-what-we-require)

* [Part 1/x: An obvious implementation based on `HashMap`.](https://github.com/frankmcsherry/blog/blob/master/posts/2016-08-03.md#part-1-an-obvious-implementation-based-on-hashmap)

* Part 2/x: A very na√Øve implementation based on sorted lists.

* Part 3/x: Organizing the data into tries.

* Part 4/x: Adding an index.

* Part 5/x: ...

I'd like to think I know exactly where this is going to end up (I have a plan), but for now let's just pretend I know the general direction, and will tell you each time we take a meaningful step.

## Part 0: Trait definitions; defining what we require.

One of the things I like doing most when writing Rust code is to write trait definitions. These are the "interfaces" of Rust, which indicate the methods and types and such required in order to actually implement "a thing". For example, we are going to spend some time defining and implementing collections, and we need to specify what methods and such these collections need to provide to be generally useful.

One nice aspect of Rust is that just writing trait definitions gives you some insight into how your implementations are going to need to work. For example, all methods in Rust clearly indicate the *ownership* of input arguments and returned output. Ownership distinguishes between variable bindings that *own* the data, and can do pretty much whatever with it (including de-allocating it), and variable bindings that only *reference* the data (the sigil `&` indicates references at work). Just writing down the method signatures gives some clarity about which types own which data, who gets to refer to them, and for how long they will be around. Each of these decisions constrains your implementation, and even at this point it helps you think out which details implementations should commit to, and which they should be able to hide.

### An example trait definition

Let's try out a trait definition for the "collection trace" functionality, something that differential dataflow uses. In order to not make you angry with details I'm not going to start with the final version. I hope this ends up clearer than otherwise, and I suspect once you see the result you may agree.

Our collection trace tracks tuples `(key, val, time, delta)` of type `(Key, Val, Time, isize)` where the types `Key`, `Val`, and `Time` get to be chosen by the person who is instantiating our type. These generic parameters are indicated in the name of the trait, written as part of its definition as:

```rust
pub trait Trace<Key, Val, Time> {

	// methods and stuff goes here

}
```

In fact our trace is not going to work for any arbitrary types; there are constraints that the types need to satisfy. For example, if we want to find keys we had best be able to test keys for equality, right? Equality testing is defined by a trait, `Eq`. We can add the constraint that whichever type `Key` gets chosen implements equality testing by adding a constraint:

```rust
pub trait Trace<Key: Eq, Val, Time> {

	// methods and stuff goes here

}
```

See how we added `: Eq` after `Key`? That means that the choice of `Key` needs to also implement the trait `Eq`, which is great to know because from this point forward we can rely on it being true, and write things like `if key1 == key2` without knowing yet which types of key we will need to use.

Our trace actually has different constraints; the keys and values are going to be *ordered*, and the times must form [a lattice](https://github.com/frankmcsherry/differential-dataflow/blob/82783d89405ed28658c6c25c98d30750dd05c2ac/src/lattice.rs#L3-L28), which is like a not-exactly-ordered set (it is a partially ordered set with some additional structure).

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	// methods and stuff goes here

}
```

Even just writing this much is helpful, because we have sorted out (or started too, at least) what needs to be true about the types we will use.

### How about adding some methods? 

Yes, let's add some methods. There are two things most collections do: add data and get data. I'm going to write some over-simple versions of these that would be great, but lack some flexibility. Our data happens to be tuples `(key,val,time,delta)`, so we are going to add and retrieve vectors of those.


```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add(&mut self, diffs: Vec<(Key, Val, Time, isize))>);

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Vec<(Key, Val, Time, isize)>;

}
```

You may notice the `&` sigil hanging around in a few places. We will get to that, but what it is saying is that when we call `add` or `get`, we are only temporarily working with `self`, the trace. Once the method returns, control of `self` returns too. Similarly, the use of `key` is only temporary access to the key. 

This contrasts with `diffs` in `add`: there is no `&` in front of the type, which means that `diffs` is actually an *owned* vector; we get to do whatever we want with it (add things to it, de-allocate it, etc). This ownership is pretty handy, because it is transitive: `diffs` also owns all of the contents of the vector, meaning all those keys and values and times and stuff. We will want to put those in our collection!

Looks pretty good! What's not to like? Well, there are a few things. 

### Type parameters: letting the user choose

Adding and returning vectors is not unreasonable, but putting that detail in the trait definition limits our implementations. Does `add` really need the results to be materialized in a vector, and does `get` really need to allocate and return ownership of memory?

Not really. I mean, they could and that might be useful, but we could be more general by indicating that all `add` really needs is a way to enumerate the items you would like to add, and all `get` really needs to return is a way for you to enumerate the results. These could be backed by vectors, but they don't have to be. There will be better choices, it will turn out.

We have already seen the techniques that we will use to improve the `add` method: generic type parameters. The method can introduce a new generic type parameter, `Iter`, whose only requirement is that it implements the `Iterator` trait with appropriately typed items, and then accepts `diffs` as an `Iter` rather than a vector:

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Vec<(Key, Val, Time, isize)>;

}
```

All that we have done here is said that when one implements `add` one needs to be able to respond to arbitrary iterator types, without relying at all on the concrete type (no `Vec`-specific methods, for example). This has the advantage that when we *use* the method, we can use whatever iterators we like, including ones that don't stage the results in one vector before inserting them (e.g., timely dataflow delivers messages as small batches, and we may want to insert the results of concatenating all of these, without copying them to another location in memory first).

Before you get all "lol iterators", these type constraints mean that methods are available statically, and can be compiled down to roughly the sort of for-loops you would write by hand. Some times they are even better (some times they are worse). But, there are real performance differences between an iterator that reads a list of block of data, and an implementation that first copies them to a second contiguous allocation.

### Associated types: letting the implementation decide

What if the `get` method wants to return an iterator, but be coy about which specific iterator type it returns? It doesn't really make sense for the user to ask for an iterator type, because it is the implementation that has to determine what gets returned. Rather, it makes sense for the implementation to define the type of the result.

In Rust traits may define "associated types", which are a bit dual to the generic type parameters that users get to specify. These are types that the implementor of the trait determines, and other than constraints on the types nothing else is exposed through the interface of the trait. We can indicate that an implementor of `Trace` must name a type for the output of `get` and that this type must implement the `Iterator` trait with approriate items, just like so:

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(Key, Val, Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Self::OutputIterator;

}
```

Notice how `get` now returns `Self::OutputIterator`, a type totally unknown to us at this point, with only the promise that any implementor of `Trace` will need to be more specific. That's fine, we can be more specific when we implement things, and Rust can stitch everything together then. The flexibility the implementors get to choose different iterator implementations is great, though.

### Returning references: learning about lifetimes

Ok, brace yourselves.

The signatures of the methods have so-far involved *owned* data. When `get` returns an iterator whose items are tuples `(key, val, time, isize)` it yields tuples whose contents are owned by the recipient. That is great for the recipient, who can now do whatever they like with the results, but it can be expensive and restrictive for the implementation.

To make this more concrete, imagine that the key type is `u64` and the value type is `String`. A `String` is dynamically sized, depending on how much stuff you stuck in there. That means that a `String` involves some dynamically allocated memory, which is usually a bit annoying to go and grab more of when you don't need to. But, through our signatures we have promised to return actual *owned* `String` types, meaning the responsibility for the memory involved is passed from the trace implementation to the recipient. Unless the trace is getting rid of its copy of the string (no) it probably needs to make a copy, because you might decide to call `.all_caps()` on it.

If the recipient (you) just needed to *look* at the `String`, you might feel a bit silly for forcing all these allocations just to subsequently de-allocate them.

This is where Rust's references come in. References are not owned data, but rather "references" to data owned by someone else. When you get a reference, you get to look at it, maybe even mutate it, but once you are done with it (and you do have to be done with it, eventually) the owner gets control back. Rust has a bunch of rules in place to make sure that when you borrow a reference no one else mutates the referenced data, and part of the joy of Rust is learning to interpret the various reasons Rust won't let you do the things you wanted to do with references.

Let's investigate this 'joy' (50-50 sarcastic-serious, so single quotes) by trying to return *references* to key, value, and time data, rather than owned instances of these types.

```rust
pub trait Trace<Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(&Key, &Val, &Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Self::OutputIterator;

}
```

We just put `&` in front of the results in the `OutputIterator` contraint. Aside: I didn't put a reference in front of the `isize` because we know we can always just copy that data.

This doesn't work, and Rust tries to help us out by saying:

	src/lib.rs:44:45: 44:49 error: missing lifetime specifier [E0106]
	src/lib.rs:44     type OutputIterator: Iterator<Item=(&Key, &Val, &Time, isize)>;
                                                          ^~~~
	src/lib.rs:44:45: 44:49 help: run `rustc --explain E0106` to see a detailed explanation

What is a lifetime specifier? You could totally run `rustc --explain E0106` to find out, and I was going to copy/paste it here but it is really quite long. Instead, I will try and explain.

Rust needs to be able to determine that references to the same data are not active at the same time, because that is what guarantees that no one is messing with your data while you are looking at it (or looking at your data while you mess with it). This is done through the concept of "lifetimes", an indication of "for how long" the reference is in play. Here "how long" is measured in "parts of your code" rather than something like real time.

For each reference you take, Rust infers the span of code for which the reference is live, and bakes that into the type. The problem here is that we haven't told Rust enough for it to figure out the lifetime for these references. Let's write something slightly less clever, but which shows where the lifetimes would come from; we will temporarily return to the more innocent time where we returned a `Vec` output rather than an iterator:

```rust
	/// retrieves differences associated with a specified key.
	fn get(&mut self, key: &Key) -> Vec<(&Key, &Val, &Time, isize)>;
```

This almost works. If it weren't for that `key` argument, Rust *would* be able to figure out the lifetimes of our outputs. 

Why? Because the only things the results could possibly refer *to* are the references supplied as inputs (or references available through them, transitively). What else could these reference possibly refer to that will still be valid after the method returns?

What is going on here, or would be going on without the `key` argument, is what Rust calls "lifetime elision", some handy rules Rust uses to remove the need to explicitly write lifetimes everywhere. But you can write them explicitly, and it is helpful to see to understand what Rust is actually doing. Let's fix that method up above with the right generic lifetimes:

```rust
	/// retrieves differences associated with a specified key.
	fn get<'a, 'b>(&'a mut self, key: &'b Key) -> Vec<(&'a Key, &'a Val, &'a Time, isize)>;
```

Whoooooaaaaa! All of the `&` things have some more noise around them! 

The most important thing to notice above is that `get` has two generic parameters, `'a` and `'b`, which are lifetime parameters. Their roles are to capture the lifetime information about the references supplied by the caller, and to say that in the vector of results, all those references have the same lifetime as the `self` reference rather than the `key` reference.

This makes a lot of sense, right? The references are totally into the trace, rather than at the query key. It's cool, all we need to do is tell Rust that. In exchange, Rust will make sure no one accidentally puts `key` into the result vector, as its referrent might get mutated or invalidated as we spin around a loop. 

You wouldn't do that, of course. I trust you, but Rust doesn't.

So, we need to put some `'a` things in front of our references to make Rust happy. For "reasons", we need to add it as a generic parameter for the trait, rather than the method. What reasons? Because the `OutputIterator` type constraint depends on `'a`, not just the `get` method, and Rust doesn't yet allow associated types to have generic parameters (part of "higher kinded types" or something).

```rust
pub trait Trace<'a, Key: Ord, Val: Ord, Time: Lattice> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(&'a Key, &'a Val, &'a Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&'a mut self, key: &Key) -> Self::OutputIterator;

}
```

You might be a bit stressed that "how can we known which `'a` we will need" to which the answer is just "no worries, we will implement the trait for all `'a`", which is a great thing that computers can do.

What is the last remaining issue? The types parameters `Key`, `Val`, and `Time` need some more constraints on them now. 

	src/lib.rs:33:1: 66:2 error: the parameter type `Key` may not live long enough [E0309]
	src/lib.rs:33 pub trait Trace<'a, Key: Ord, Val:Ord, Time: Lattice> {
	              ^
	src/lib.rs:33:1: 66:2 help: run `rustc --explain E0309` to see a detailed explanation
	src/lib.rs:33:1: 66:2 help: consider adding an explicit lifetime bound `Key: 'a`...
	src/lib.rs:33:1: 66:2 note: ...so that the type `Key` will meet its required lifetime bounds

What Rust is telling us now is that because we are thinking about returning types like `&'a Key` we have to promise that `Key` itself is actually valid for all of the lifetime `'a`. We could make `Key` something horrible like `&'b String` for some other `'b`, at which point the reference `&'a Key` wouldn't actually be to valid data. You probably weren't thinking you would do this, but Rust was. Rust is protecting you from weird creative you, and from your weird creative co-workers, and the weird creative unintended interactions of your code with theirs.

The fix is pretty simple:

```rust
pub trait Trace<'a, Key: Ord+'a, Val: Ord+'a, Time: Lattice+'a> {

	/// incorporates a new bunch of differences into the trace.
	fn add<Iter: Iterator<Item=(Key, Val, Time, isize)>>(&mut self, diffs: Iter);

	/// An iterator defined by the implementation to produce results.
	type OutputIterator: Iterator<Item=(&'a Key, &'a Val, &'a Time, isize)>;

	/// retrieves differences associated with a specified key.
	fn get(&'a mut self, key: &Key) -> Self::OutputIterator;

}
```

The constraint `Key: Ord+'a` means that `Key` needs to implement `Ord` and live at least as long as `'a`, which mostly just means it can't contain references that might last less long. Typically `Key` is going to be some owned data like `u64` or `String` or even `Vec<Vec<Option<String>>>`, all of which satisfy this constraint.

### An observation

This whole section may give some insight into the Rust debugging process. We have done a lot of up-front work defining our trait, and scoping out several potential issues that Rust has already forced us to fix by making our method prototypes more specific. I would say that the majority of my time debugging Rust code is spent like this. I've literally spent zero time in an actual debugger, and once written while not necessarily correct, your code pretty much does what it says.

## Part 1: An obvious implementation based on `HashMap`

Just to start things out, and before trying to be clever at all, let's write an implementation of our trait using Rust's built in `HashMap`. This implementation will be pretty simple, but wasteful with respect to memory usage, and misses out on some important properties we will want for later on. But, it is a simple example of perhaps the most obvious implementation.

This also gives us a chance to see how to implement traits in Rust, before we start doing harder things.

To implement a trait for a type, here a hashmap from keys of type `K` to vectors of `(V, T, isize)` elements, you write something like so:

```rust
impl<'a, K, V, T> Trace<'a, K, V, T> for HashMap<K, Vec<(V, T, isize)>> {
	
	// implementation of methods and stuff goes here

}
```

We just need to add constraints on the type parameters and implement the methods, and we should be good to go. 

### Implementing the methods

We have two methods to implement, `add` and `get`. We know what they are going to look like because of the trait's signature, so let's write down some empty bodies.

```rust
impl<'a, K, V, T> Trace<'a, K, V, T> for HashMap<K, Vec<(V, T, isize)>> {

	fn add<Iter: Iterator<Item=(K, V, T, isize)>>(&mut self, diffs: Iter) {
		unimplemented!()
	}

	fn get(&'a mut self, key: &K) -> Self::OutputIterator {
		unimplemented!()
	}

}
```

These `unimplemented!()` things are macros indicating the code isn't written yet. They are totally optional, but allow your code to compile without actually returning the right thing yet (`Self::OutputIterator`, which is also not written yet).

#### The `add` method

Here is what I would do for the `add` method: 

```rust
	fn add<Iter: Iterator<Item=(K, V, T, isize)>>(&mut self, diffs: Iter) {
		for (key, val, time, delta) in diffs {
			self.entry(key)
				.or_insert(Vec::new())
				.push((val, time, delta));
		}
	}
```

There is some syntactic sugar in the form of the `for .. in ..` construct for iterators; because `Iter` implements `Iterator`, we can just use the for loop.

We've also used `HashMap`'s functionality to pretty ergonomically try to find the entry associated with a key, create one if it doesn't exist, and the push the value, time, and delta triple to the end of the list.

This was pretty painless, but we got lucky in a few ways. The `entry` method requires an *owned* instance of `K` because if the entry doesn't exist we need to add it, and the hash map will need to hold on to a copy of the key in that case. However there is only one owned instance of the key for each element in `diffs`, so we were pretty smart to only stash the `(val, time, delta)` triple.

If we tried to use the key twice we would get an error from Rust indicating that we are trying to re-use a variable which has been moved somewhere else. We could consider copying or cloning the key, but that functionality lies behind traits we haven't required of the type `K` yet.

#### The `get` method

The `get` method is going to turn into a pain in the butt, mostly because of the restrictive way Rust's `HashMap` is implemented. We will fight against it a little bit, explain how it could be done, and then walk away because we don't really want to be using `HashMap` anyhow.

Here is what we would like to write:

```rust
	fn get(&'a mut self, key: &K) -> Self::OutputIterator {
		Self::OutputIterator::new(self.get(key))
	}
```

This looks up `key` in `self` and returns an `Option<&'a Vec<(V, T, isize)>>`. We can use that reference in our output iterator! In particular, a `&'a Vec<(V, T, isize)>` gives us access to all the `&'a V` and `&'a T` references contained therein.

The problem is we don't have a `&'a K` anywhere. That `key` argument is a reference, but not with the right lifetime (remember the cautionary tale from the previous section?). The key obviously exists in the `HashMap`, but we can't get a reference to it because `HashMap`'s interface is a bit restrictive. There is a way to get a reference to a key once you've used the `entry` method up above, but that requires an owned key to call in the first place. We can't even stash a second copy of the key in the list with the `(V, T, isize)` tuples because we can't copy or clone it.

Sucks. 

We could consider changing the iterator in the trait definition to be 

```rust
	Iter: Iterator<Item=(&'a V, &'a T, isize)>
```

because we know that users must have a `&K` on hand to call the `get` method. That isn't a horrible idea, but it is limiting; the user has to make sure to match up their keys with the iterators' values, even though we have a reference to the right key in the hash map.

Since we aren't acutally going to use this version of the code, let's imagine that the `HashMap`'s `get` method return a reference to both the key and the value, rather than just the value. We still get to write:

```rust
	fn get(&'a mut self, key: &K) -> Self::OutputIterator {
		Self::OutputIterator::new(self.get(key))
	}
```

because we are just passing the buck to the `OutputIterator` type's `new` method, which we will see next.

### Implementing the types

The `OutputIterator` type isn't going to be wildly complicated. In fact, we could possibly borrow some existing iterator implementations, but we will just roll our own to see how it works. 

The first thing to do is to define the struct that holds the data we will need for iteration.

```rust
/// iterates over tuples of references
pub struct OutputIter<'a, K:'a, V:'a, T:'a> {
	data: Option<(&'a K, &'a Vec<(V, T, isize)>, usize)>
}
```

The `data` field here is, optionally, a triple of: key reference, vector reference, and a `usize` for remembering where we are in the vector. As we advance through the iterator we will increment this `usize`, and stop when it reaches the length of the vector. 

The field is an `Option` type, which can either be `Some(x)` for some data `x`, or `None` indicating that there is nothing there. The option is important here because `get` does need to return a valid instance of `OutputIter` even when the key is absent and no `&'a K` even exists. We could change our `get` trait to return an `Option<Self::OutputIterator>`, or we can just make our iterator return nothing.

Let's first write the `new` method we know we need:

```rust
impl<'a, K:'a, V:'a, T:'a> OutputIter<'a, K, V, T> {
	pub fn new(input: Option<(&'a K, &'a Vec<(V, T, isize)>)>) -> Self {
		OutputIter {
			data: input.map(|(key, vec)| (key, vec, 0))
		}
	}
}
```

Here we see for the first time struct field initialization; the `data` field of an `OutputIter`.
We take in the type produced by `HashMap`'s hypothetical `get` method, and use `map` which applies some logic to the internals of an `Option` type, where in this case we've just put a zero in for the current position. In case `input` is `None`, we just end up with a `None` output and no logic applied.

All we need to do to make `OutputIter` into an iterator is implement the `Iterator` trait. It's really not that hard; I've written the skeleton here to give you a sense for all that is needed:

```rust
impl<'a, K:'a, V:'a, T:'a> Iterator for OutputIter<'a, K, V, T> {

	type Item = (&'a K, &'a V, &'a T, isize);

	fn next(&mut self) -> Option<Self::Item> {

	}

}
```

An implementation needs to indicate the type of the `Item` it will enumerate, and a function that produces the next item or `None` if the iterator has finished. 

```rust
impl<'a, K:'a, V:'a, T:'a> Iterator for OutputIter<'a, K, V, T> {

	type Item = (&'a K, &'a V, &'a T, isize);

	fn next(&mut self) -> Option<Self::Item> {
		if let Some((ref key, ref vec, ref mut pos)) = self.data {
			if *pos < vec.len() {
				*pos += 1;
				let vtd = &vec[*pos-1];
				Some((key, &vtd.0, &vtd.1, vtd.2))
			}
			else {
				None
			}
		}
		else {
			None
		}
	}
}
```

The `if let` construction is a neat thing Rust borrowed from Swift (perhaps "copied" would be more accurate, or "cloned" depending on your views on whether ideas have owners). The construct fires if the pattern matches, in this case if `self.data` is in fact something. At the same time, it binds `key`, `vec`, and `pos` to references to the fields of the something. In the case of `pos` it is even a mutable reference. The `ref` keyword might be a bit confusing, but I guess the Rust folks thought it was better than `*`, which is logically what you want there (bind `key`, `val`, `pos` to things that derefence to the fields).

This trait implementation is all it takes to be an iterator. 

If you use this type in your code, perhaps by calling `get` on our `HashMap` implementation of `Trace`, Rust will go track down this code and use it directly. For example, imagine your value and time types are stack-allocated, like maybe `u64`s or something, and you write the following code:

```rust
let mut dataz = Vec::new();
for (k,v,t,d) in trace.get(&my_key) {
	dataz.push(v.clone(), t.clone(), d);
}
```

In principle Rust (via LLVM) is able to realize that (i) if the iterator's `Option` is `Some` it stays `Some` and that test can be hoisted out of the loop, (ii) the "increment and test against length" pattern is just walking through an array, and (iii) your key, time, and delta accesses have the same layout as where they are stored. All of these combine to allow LLVM to optimize your loop down to a conditional `memcpy`, just checking if your key is present in the `HashMap` and then `memcpy`ing the results if so.

That's pretty neat. It's the sort of thing you might implement by hand in other languages in order to have awesome performance. Instead, you can spend your time writing blog posts about how you don't necessarily need to do that any more.

### The implementation

In addition to the definition and implementation of `OutputIter`, here is our implementation of `Trace`. 

```rust
impl<'a, K:Ord+'a, V:Ord+'a, T:Lattice+'a> Trace<'a, K, V, T> for HashMap<K, Vec<(V, T, isize)>> {

	fn add<Iter: Iterator<Item=(K, V, T, isize)>>(&mut self, diffs: Iter) {
		for (key, val, time, delta) in diffs {
			self.entry(key)
				.or_insert(Vec::new())
				.push((val, time, delta));
		}
	}

	type OutputIterator = OutputIter<'a, K, V, T>;

	fn get(&'a mut self, key: &K) -> Self::OutputIterator {
		Self::OutputIterator::new(self.get(key))
	}

}
```

One last error: to use `K` as a key in a `HashMap` it must implement `::std::hash::Hash`, the trait for hashing. So, we just `+` that into our constraints on `K` and we are good to go!

Except that `HashMap` doesn't actually have the `get` method we wanted. Oh well.

### Wrap-up

I hope this was somewhat informative about how to *implement* things in Rust. We saw some horrible sticky details in the interface mismatch between `HashMap` and `Trace`, where obviously I like my version more but the Rust folks probably have opinions too. My recollection is that they felt the ergonomics of `get` were important as `HashMap` would be used a lot, and so while expressivity is good too, overwhelming people in such a commonly used class might suck.

In addition to the limited interface, there are other things not to like about a `HashMap` implementation. A `HashMap` uses a lot more memory than we want to use; if a key has just one value, well you can do the math on how much this requires (hint: lots). Also, `HashMap` maintains its keys in something of a weird order; it makes sense when you reverse it out, but it makes it painful to pre-arrange keys to provide sequential access. The `Vec` values also result in lots of random access as locality in the hash map means little for the memory they manage.

## Part 2: A very na√Øve version based on sorted lists.

Let's write a relatively na√Øve implementation of our `Trace` trait using sorted lists.

Coming soon!

## Part 3: Organizing the data into tries.

Coming later!

## Part 4: Adding an index.

Coming even later!